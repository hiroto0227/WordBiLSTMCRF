### use # to comment out the configure item

### I/O ###
train_dir=/home/sekine/WordLevelChemdner/Repository/SeqData/train.bioes
dev_dir=/home/sekine/WordLevelChemdner/Repository/SeqData/valid.bioes
test_dir=/home/sekine/WordLevelChemdner/Repository/SeqData/test.bioes
model_dir=/home/sekine/WordLevelChemdner/Repository/TrainedModel/bilstmcrf_charlstm
word_emb_dir=/home/sekine/WordLevelChemdner/Repository/Pretrained/watanabe.word2vec.dim50

### SubWord ###
sw_num=0
sentence_piece_dirs=[]
sw_emb_dirs=[]

### Normalize ###
norm_word_emb=False
norm_char_emb=False
number_normalized=True
seg=True
word_emb_dim=50
char_emb_dim=30
sw_emb_dim=50

###NetworkConfiguration###
use_crf=True
use_char=True
word_seq_feature=LSTM
char_seq_feature=LSTM

###TrainingSetting###
status=train
optimizer=SGD
iteration=50
batch_size=10
ave_batch_loss=False

###Hyperparameters###
char_hidden_dim=50
sw_hidden_dim=50
hidden_dim=200
dropout=0.5
lstm_layer=1
bilstm=True
learning_rate=0.015
lr_decay=0.0001
momentum=0
l2=1e-8
gpu=True
clip=5.0
