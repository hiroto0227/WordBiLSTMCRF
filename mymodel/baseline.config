train_path="/home/sekine/WordLevelChemdner/Repository/SeqData/train.csv"
#train_path="/home/sekine/watanabe/DATA/train.txt"
test_path="/home/sekine/WordLevelChemdner/Repository/SeqData/test.csv"
#test_path="/home/sekine/watanabe/DATA/test.txt"
predicted_path="/home/sekine/WordLevelChemdner/Repository/SeqData/predicted.csv"
batchsize=10
epoch=50
word_embed_dim=50
char_embed_dim=30
token_embed_dim=50
word_lstm_dim=200
char_lstm_dim=50
token_lstm_dim=50
dropout=0.5
initial_rate = 0.015
weight_decay = 0.000001
save_model = "/home/sekine/WordLevelChemdner/Repository/TrainedModel/baseline.model"
load_model = "/home/sekine/WordLevelChemdner/Repository/TrainedModel/baseline.model"
#word2vec_path="/home/sekine/watanabe/DATA/chemdner_pubmed_drug.word2vec_model_token4_d50"
word2vec_path="/home/sekine/WordLevelChemdner/Repository/Pretrained/gv_pretrain_regex.model"
gpu=2
